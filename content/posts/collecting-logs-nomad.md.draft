+++
title = "Collecting Logs in Nomad cluster"
date = 2019-06-29T18:10:55+05:30
type = "post"
description = "Collect logs from applications running on Nomad cluster using docker task driver with the help of journald and vector"
in_search_index = true
[taxonomies]
tags= ["Devops", "Nomad"]
+++

This week, I was observing a few issues in my Vector pipeline where the logs from a new container weren't being ingested by Vector. Vector essentially talks to docker daemon socket to fetch container logs using the [ContainerLogs](https://docs.docker.com/engine/api/v1.41/#operation/ContainerLogs) endpoint. This also means that if you've super short lived containers (like batch jobs), there are chances that Vector won't ingest them as I documented in [this issue](https://github.com/vectordotdev/vector/issues/11876).

This meant that I needed to explore some other possibilities because losing logs in a cluster isn't something ideal. There are a few different approaches that I could think of:

- Use a sidecar approach, collect logs from the container in some shared directory. In Nomad, tasks in the same group can share the same filesystem and you can also run two containers with same Task directory using the sidecar approach. However this meant that I needed to tweak the application to log to a file instead of stdout. This wasn't ideal because the cluster had many such apps so making changes in each of them isn't ideal or required as well. Containers are expected to log to stdout using the 12 Factor approach as well. (https://12factor.net/logs). I might be missing something here, because I've seen the sidecar approach being recommended a lot - but it has very obvious downsides too.

Another well known reason to not use a sidecar is that you'll add overhead of resources (CPU/Mem) for each application. What could be done centrally is now being done n\*namespace times. Also that means the deployment job spec for each application has to change, have to orchestrate the version upgrades/config upgrades across each of these. IMHO, sidecar approach would make sense in a very very limited usecase and should not be used as unless you really have a specific reason to do it.

- Use a different logging driver. Nomad supports tweaking the log driver of Docker (when using the Docker task plugin). There are quite a few options here, but using `journald` made the most sense. Live tailing of docker logs is supported only with `json-file` and `journald`.

I chose to go with tweaking logging driver. The steps to do that are quite straightforward

- Change the `config` stanza inside `plugin` config for Nomad. You can do this per task basis too if you want, but since I am centrally collecting logs - tweaking this setting at the global level made sense.
